{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2393be-988d-4553-a1e9-d98522d8ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csenge2/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from functools import partial\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from data_tools import dataset_with_mask \n",
    "from unet import UNet\n",
    "from custom_losses import IoULoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0857d671-0bdc-4495-8373-a2a26fb83330",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6cb9dc-845b-4624-b9ff-8e28cdef531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUM = 10\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1351b7c5-21d9-49bd-ac78-f6a04c7a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.load(open('mask_train.json'))\n",
    "val_json = json.load(open('mask_val.json'))\n",
    "test_json = json.load(open('mask_test.json'))\n",
    "\n",
    "train_folder = '/mnt/NVME4/vizilabda_videos/Mask_RCNN/train'\n",
    "val_folder = '/mnt/NVME4/vizilabda_videos/Mask_RCNN/val'\n",
    "test_folder = '/mnt/NVME4/vizilabda_videos/Mask_RCNN/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5153d379-4fe8-43be-b131-571f9ae0f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self,folder, json, ratio = 0.5, transforms=None):\n",
    "\n",
    "        self.whole_dict = json\n",
    "        self.ratio = ratio\n",
    "        self.folder = folder\n",
    "        self.transforms = transforms\n",
    "        self.img_data = json\n",
    "        self.fnames = []\n",
    "        for key in list(json.keys()):\n",
    "            self.fnames.append(key)\n",
    "            \n",
    "        self.fnames.sort()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data)\n",
    "\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        fname = self.fnames[idx]\n",
    "        png_path = os.path.join(self.folder,fname)\n",
    "\n",
    "        png = cv2.imread(png_path)\n",
    "        png = cv2.resize(png, (0,0), fx=self.ratio, fy=self.ratio) \n",
    "        image = transforms.functional.to_tensor(np.array(png))\n",
    "\n",
    "        if self.transforms:\n",
    "              image = self.transforms(image)\n",
    "\n",
    "        label = np.zeros([int(1080*self.ratio),int(1920*self.ratio), 1])\n",
    "        for max_y,max_x,min_y,min_x in self.img_data[fname]:\n",
    "            try:\n",
    "                max_y = int(max_y * 1080 * self.ratio)\n",
    "                max_x = int(max_x * 1920 * self.ratio)\n",
    "                min_y = int(min_y * 1080 * self.ratio)\n",
    "                min_x = int(min_x * 1920 * self.ratio)\n",
    "                label[min_y:max_y,min_x:max_x,:] = 1\n",
    "            except:\n",
    "                print('ERROR WITH LABELS')\n",
    "        label = transforms.functional.to_tensor(np.array(label))\n",
    "        \n",
    "        #print(fname, label)\n",
    "        return image, label, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f074098e-8f18-41a2-8ecf-cf7880bcb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset(train_folder,train_json,ratio = 0.25)\n",
    "val_ds = dataset(val_folder,val_json,ratio = 0.25)\n",
    "test_ds = dataset(test_folder,test_json,ratio = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb6d7a3-27b5-46b9-a4ee-2006444bf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_ds, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "val_iterator = DataLoader(val_ds, \n",
    "                                batch_size = BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_ds, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef34f227-2611-4966-a627-70d6a8cc3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = seq_model#.to(device)\n",
    "#criterion = nn.MSELoss()#.to(device)\n",
    "#criterion = nn.L1Loss(reduction = 'none').to(device)\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=1,\n",
    "             n_blocks=2,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2)\n",
    "#optimizer = optim.Adam(model.parameters(),lr=0.0005)\n",
    "#optimizer = optim.Adagrad(model.parameters(),lr=0.001)\n",
    "#net.load_state_dict(torch.load('net_epoch1_0_loss=0.0258271936327219.pt'))\n",
    "\n",
    "# criterion\n",
    "criterion = IoULoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78674c-ceae-4d95-be23-b6bafa46266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = 1\n",
    "for epoch in range(EPOCH_NUM): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_iterator, 0):\n",
    "        inputs, labels,fnames = data[0].cuda(), data[1].cuda(),data[2]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).cuda()\n",
    "        #print(np.amin(inputs.cpu().detach().numpy()),np.amax(inputs.cpu().detach().numpy()))\n",
    "        #print(inputs.shape,labels.shape,outputs.shape)\n",
    "        \n",
    "        #print(outputs.shape,labels.shape)\n",
    "        \n",
    "        loss_ops = torch.squeeze(outputs,dim=1)\n",
    "        loss_labs = torch.squeeze(labels,dim=1)\n",
    "        loss = criterion(loss_ops,loss_labs)#.permute(0,2,1).type(torch.DoubleTensor).to(device), labels.type(torch.DoubleTensor).to(device)).mean(dim=1)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        prev_loss = 1\n",
    "        if i % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.7f' % (epoch + 1, i + 1, running_loss/10))\n",
    "            \n",
    "            '''img = inputs[7].cpu().detach().numpy()\n",
    "            label = labels[7].cpu().detach().numpy()\n",
    "            pred = outputs[7].cpu().detach().numpy()\n",
    "            print(np.amin(pred),np.amax(pred))\n",
    "            \n",
    "            img = np.moveaxis(img,0,-1)\n",
    "            label = np.moveaxis(label,0,-1)\n",
    "            pred = np.moveaxis(pred,0,-1)\n",
    "            \n",
    "            img = np.stack((img[:,:,2],img[:,:,1],img[:,:,0]),axis=2)\n",
    "            \n",
    "            SI = superimpose_mask(img,label,color_index = 0,grayscale=False) # ground truth: piros\n",
    "            SI = superimpose_mask(SI,pred,color_index = 1,grayscale=False) # predikció: zöld\n",
    "            \n",
    "            plt.figure(figsize = (20,15))\n",
    "            plt.imshow(SI)\n",
    "            '''\n",
    "                \n",
    "            running_loss = 0.0\n",
    "        \n",
    "    for i, data in enumerate(val_iterator, 0):\n",
    "        inputs, labels,fnames = data[0].cuda(), data[1].cuda(),data[2]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        prev_loss = 1\n",
    "\n",
    "    print('validation loss: %.7f' % (running_loss / i))\n",
    "    if running_loss/i < val_loss:\n",
    "        print('SAVE')\n",
    "        torch.save(model.state_dict(),\"otf_model_net_epoch\"+str(epoch)+'_loss='+str(float(running_loss/i))+'.pt')\n",
    "        val_loss = running_loss/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fc95b-b99d-40ad-a264-bc4fb6086e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset(train_folder,train_json,ratio = 0.25)\n",
    "val_ds = dataset(val_folder,val_json,ratio = 0.25)\n",
    "test_ds = dataset(test_folder,test_json,ratio = 0.25)\n",
    "train_iterator = data.DataLoader(train_ds, \n",
    "                                 batch_size = 1)\n",
    "val_iterator = data.DataLoader(val_ds, \n",
    "                                batch_size = 1)\n",
    "test_iterator = data.DataLoader(test_ds, \n",
    "                                batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a47b8e-12e3-46e2-a4e8-94f2960d816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNet': {'in_channels': 3, 'out_channels': 1, 'n_blocks': 2, 'start_filters': 32, 'activation': 'relu', 'normalization': 'batch', 'conv_mode': 'same', 'dim': 2, 'up_mode': 'transposed'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('otf_model_net_epoch8_loss=0.6656731444160158.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb418499-c356-4624-846b-6259d5d60d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_folder = '/mnt/NVME4/vizilabda_videos/Mask_RCNN/mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ee28cb-5367-4ae6-a615-1e45e011e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_color(col_len,col_idx):\n",
    "    if col_len<= col_idx:\n",
    "        col_idx = assert_color(col_len,col_idx-1)\n",
    "    return col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ac3fad-3d0a-4b7a-9c60-893479ef3292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [17:09,  5.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.ndimage import label\n",
    "colors = [[255,255,255],[255,255,0],[255,0,255],[0,255,255],\n",
    "          [0,0,255],[0,255,0],[255,0,0],[0,0,0],\n",
    "          [125,125,125],[125,125,0],[125,0,125],[0,125,125],\n",
    "          [0,0,125],[0,125,0],[125,0,0]]\n",
    "for i, data in tqdm(enumerate(train_iterator, 0)):\n",
    "        inputs, labels,fnames = data[0].cuda(), data[1].cuda(),data[2]\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = (outputs > 80) * 1\n",
    "        for i in range(outputs.shape[0]):\n",
    "            fname = fnames[i]\n",
    "            op = outputs[i,0,:,:].astype(np.uint8)\n",
    "            op = cv2.resize(op, (0,0), fx=4, fy=4) \n",
    "            instances,num = label(op)\n",
    "            r_channel = np.zeros(op.shape)\n",
    "            g_channel = np.zeros(op.shape)\n",
    "            b_channel = np.zeros(op.shape)\n",
    "            for idx in range(num):\n",
    "                if idx<len(colors):\n",
    "                    col_idx = idx\n",
    "                else:\n",
    "                    col_idx = idx - len(colors) \n",
    "                if col_idx >= len(colors):\n",
    "                    col_idx = assert_color(len(colors),col_idx)\n",
    "                col = colors[col_idx]\n",
    "                r_channel += (instances == idx+1) * col[0] \n",
    "                g_channel += (instances == idx+1) * col[1] \n",
    "                b_channel += (instances == idx+1) * col[2] \n",
    "            \n",
    "            res = np.stack((b_channel,g_channel,r_channel),axis=2)\n",
    "            res == res.astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(mask_folder,fname),res)\n",
    "            \n",
    "                \n",
    "        \n",
    "        #with open(os.path.join('/mnt/NVME4/vizilabda_videos/Mask_RCNN/mask',fnames[0][:-4]+'.npy'),'wb') as f:\n",
    "            #np.save(f,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f2827-a198-4e7e-9a02-1baf6e6b8eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osc_new",
   "language": "python",
   "name": "osc_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
