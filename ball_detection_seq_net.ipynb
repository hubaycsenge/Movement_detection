{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "\n",
    "from trd.utils import use_gpu\n",
    "\n",
    "\n",
    "from seq_net import *\n",
    "from data_tools import dataset_with_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/mnt/LAIN_EXTERNAL2/waterpolo_anyagok/vizilabda_meccsek/frames'\n",
    "BATCH_SIZE = 8\n",
    "EPOCH_NUM = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.load(open('train.json'))\n",
    "val_json = json.load(open('val.json'))\n",
    "test_json = json.load(open('test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset_with_corners(folder,train_json)\n",
    "val_ds = dataset_with_corners(folder,val_json)\n",
    "test_ds = dataset_with_corners(folder,test_json)\n",
    "\n",
    "train_iterator = data.DataLoader(train_ds, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "val_iterator = data.DataLoader(val_ds, \n",
    "                               batch_size = BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_ds, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.SmoothL1Loss().to(device)\n",
    "model = seq_model\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csenge/.local/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.0012330\n",
      "(0.005841678008437157, 0.05452651530504227) (0.013849986717104912, -0.0011330305133014917)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(11, 59) (27, -1)\n",
      "[1,   201] loss: 0.0512151\n",
      "(0.45400384068489075, 0.3892158567905426) (0.5590235590934753, 0.4291027784347534)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(872, 420) (1073, 463)\n",
      "[1,   401] loss: 0.0057448\n",
      "(0.7544519305229187, 0.4328368008136749) (0.7711896896362305, 0.47489356994628906)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1449, 467) (1481, 513)\n",
      "validation loss: 0.0314307\n",
      "SAVE\n",
      "[2,     1] loss: 0.0000458\n",
      "(0.6932628154754639, 0.4162004888057709) (0.7114377021789551, 0.45320814847946167)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1331, 449) (1366, 489)\n",
      "[2,   201] loss: 0.0058665\n",
      "(0.5753222703933716, 0.3814900517463684) (0.5989092588424683, 0.42165547609329224)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(1105, 412) (1150, 455)\n",
      "[2,   401] loss: 0.0057894\n",
      "(0.7478881478309631, 0.43391138315200806) (0.7696972489356995, 0.47517073154449463)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1436, 469) (1478, 513)\n",
      "validation loss: 0.0268351\n",
      "SAVE\n",
      "[3,     1] loss: 0.0000473\n",
      "(0.6814737319946289, 0.4295491576194763) (0.6994780898094177, 0.47539910674095154)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1308, 464) (1343, 513)\n",
      "[3,   201] loss: 0.0051063\n",
      "(0.5596160888671875, 0.3938286006450653) (0.5877458453178406, 0.4355047047138214)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(1074, 425) (1128, 470)\n",
      "[3,   401] loss: 0.0045366\n",
      "(0.7510706782341003, 0.42321521043777466) (0.7689173817634583, 0.4677797555923462)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1442, 457) (1476, 505)\n",
      "validation loss: 0.0257556\n",
      "SAVE\n",
      "[4,     1] loss: 0.0000483\n",
      "(0.6728193163871765, 0.44143378734588623) (0.6933287382125854, 0.49032101035118103)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1292, 477) (1331, 530)\n",
      "[4,   201] loss: 0.0033945\n",
      "(0.5262713432312012, 0.39172959327697754) (0.5666599869728088, 0.4470434784889221)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(1010, 423) (1088, 483)\n",
      "[4,   401] loss: 0.0034303\n",
      "(0.7415229082107544, 0.4157049357891083) (0.7679003477096558, 0.46085476875305176)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1424, 449) (1474, 498)\n",
      "validation loss: 0.0245996\n",
      "SAVE\n",
      "[5,     1] loss: 0.0000463\n",
      "(0.6701809763908386, 0.44038277864456177) (0.7011836767196655, 0.49332088232040405)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1287, 476) (1346, 533)\n",
      "[5,   201] loss: 0.0022708\n",
      "(0.4960249662399292, 0.383476585149765) (0.5167254209518433, 0.44935211539268494)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(952, 414) (992, 485)\n",
      "[5,   401] loss: 0.0029414\n",
      "(0.7411075830459595, 0.4095984101295471) (0.7586527466773987, 0.4523521959781647)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1423, 442) (1457, 489)\n",
      "validation loss: 0.0201438\n",
      "SAVE\n",
      "[6,     1] loss: 0.0000434\n",
      "(0.6812328696250916, 0.45337963104248047) (0.6944448947906494, 0.5061800479888916)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1308, 490) (1333, 547)\n",
      "[6,   201] loss: 0.0019166\n",
      "(0.4711270034313202, 0.4088006615638733) (0.49215972423553467, 0.4432549476623535)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(905, 442) (945, 479)\n",
      "[6,   401] loss: 0.0025966\n",
      "(0.734593391418457, 0.4020676910877228) (0.7488371729850769, 0.447410523891449)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1410, 434) (1438, 483)\n",
      "validation loss: 0.0177296\n",
      "SAVE\n",
      "[7,     1] loss: 0.0000394\n",
      "(0.6847110390663147, 0.4688528776168823) (0.7060467600822449, 0.5034844279289246)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1315, 506) (1356, 544)\n",
      "[7,   201] loss: 0.0016396\n",
      "(0.4489399194717407, 0.40846917033195496) (0.46813106536865234, 0.43644028902053833)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(862, 441) (899, 471)\n",
      "[7,   401] loss: 0.0022569\n",
      "(0.7224708795547485, 0.39114803075790405) (0.7445919513702393, 0.44512975215911865)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1387, 422) (1430, 481)\n",
      "validation loss: 0.0173028\n",
      "SAVE\n",
      "[8,     1] loss: 0.0000299\n",
      "(0.7057701945304871, 0.4758310317993164) (0.7353270053863525, 0.5116616487503052)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1355, 514) (1412, 553)\n",
      "[8,   201] loss: 0.0013970\n",
      "(0.4233788847923279, 0.40033215284347534) (0.43832850456237793, 0.42847931385040283)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(813, 432) (842, 463)\n",
      "[8,   401] loss: 0.0021082\n",
      "(0.7207174301147461, 0.3958725035190582) (0.7482474446296692, 0.447540819644928)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1384, 428) (1437, 483)\n",
      "validation loss: 0.0171467\n",
      "SAVE\n",
      "[9,     1] loss: 0.0000215\n",
      "(0.7390540838241577, 0.4832300543785095) (0.7572615146636963, 0.5042915940284729)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1419, 522) (1454, 545)\n",
      "[9,   201] loss: 0.0012460\n",
      "(0.42193126678466797, 0.4031980335712433) (0.433762788772583, 0.43587708473205566)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(810, 435) (833, 471)\n",
      "[9,   401] loss: 0.0017995\n",
      "(0.7151384353637695, 0.39938071370124817) (0.7495049238204956, 0.4386996626853943)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1373, 431) (1439, 474)\n",
      "validation loss: 0.0172135\n",
      "[10,     1] loss: 0.0000164\n",
      "(0.7623379230499268, 0.48471954464912415) (0.7751239538192749, 0.5135742425918579)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1464, 523) (1488, 555)\n",
      "[10,   201] loss: 0.0011525\n",
      "(0.405195027589798, 0.4022430181503296) (0.41834673285484314, 0.43607640266418457)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(778, 434) (803, 471)\n",
      "[10,   401] loss: 0.0015577\n",
      "(0.7315570712089539, 0.3991478681564331) (0.7439326047897339, 0.43345171213150024)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1405, 431) (1428, 468)\n",
      "validation loss: 0.0167101\n",
      "SAVE\n",
      "[11,     1] loss: 0.0000115\n",
      "(0.7918772101402283, 0.4695155620574951) (0.7965096831321716, 0.52232825756073)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1520, 507) (1529, 564)\n",
      "[11,   201] loss: 0.0010523\n",
      "(0.39778974652290344, 0.39624834060668945) (0.4151780903339386, 0.44252824783325195)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(764, 428) (797, 478)\n",
      "[11,   401] loss: 0.0014235\n",
      "(0.7351765632629395, 0.4042162001132965) (0.7484319806098938, 0.4299931824207306)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1412, 437) (1437, 464)\n",
      "validation loss: 0.0168545\n",
      "[12,     1] loss: 0.0000088\n",
      "(0.8073471188545227, 0.4689462184906006) (0.8128348588943481, 0.5214868783950806)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1550, 506) (1561, 563)\n",
      "[12,   201] loss: 0.0009439\n",
      "(0.38915443420410156, 0.3847578167915344) (0.4076533913612366, 0.4347759783267975)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(747, 416) (783, 470)\n",
      "[12,   401] loss: 0.0012473\n",
      "(0.7351396679878235, 0.3985552191734314) (0.7674220204353333, 0.4201197326183319)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1411, 430) (1473, 454)\n",
      "validation loss: 0.0160261\n",
      "SAVE\n",
      "[13,     1] loss: 0.0000091\n",
      "(0.806605339050293, 0.4771128296852112) (0.8109608292579651, 0.507840096950531)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1549, 515) (1557, 548)\n",
      "[13,   201] loss: 0.0008468\n",
      "(0.37560179829597473, 0.3995823264122009) (0.4007509648799896, 0.4530211389064789)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(721, 432) (769, 489)\n",
      "[13,   401] loss: 0.0010767\n",
      "(0.7400447130203247, 0.39795851707458496) (0.768642008304596, 0.42632174491882324)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1421, 430) (1476, 460)\n",
      "validation loss: 0.0162869\n",
      "[14,     1] loss: 0.0000062\n",
      "(0.8249241709709167, 0.4702644646167755) (0.8313373327255249, 0.5217515826225281)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1584, 508) (1596, 563)\n",
      "[14,   201] loss: 0.0007680\n",
      "(0.3716692328453064, 0.41382554173469543) (0.4046240746974945, 0.4694540202617645)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(714, 447) (777, 507)\n",
      "[14,   401] loss: 0.0009420\n",
      "(0.7469279170036316, 0.3984922766685486) (0.7730438709259033, 0.4230346381664276)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1434, 430) (1484, 457)\n",
      "validation loss: 0.0160143\n",
      "SAVE\n",
      "[15,     1] loss: 0.0000051\n",
      "(0.8375912308692932, 0.4671180844306946) (0.8415926694869995, 0.5143644213676453)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1608, 504) (1616, 556)\n",
      "[15,   201] loss: 0.0007048\n",
      "(0.37047624588012695, 0.41714778542518616) (0.40460437536239624, 0.4731141924858093)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(711, 451) (777, 511)\n",
      "[15,   401] loss: 0.0008538\n",
      "(0.749996542930603, 0.4019325077533722) (0.7710595726966858, 0.4335406422615051)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1440, 434) (1480, 468)\n",
      "validation loss: 0.0154266\n",
      "SAVE\n",
      "[16,     1] loss: 0.0000039\n",
      "(0.8654669523239136, 0.46196556091308594) (0.8523909449577332, 0.5159934163093567)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1662, 499) (1637, 557)\n",
      "[16,   201] loss: 0.0006415\n",
      "(0.3692181408405304, 0.4270796775817871) (0.41245394945144653, 0.48154568672180176)\n",
      "(0.39375001192092896, 0.44907405972480774) (0.41614583134651184, 0.49166667461395264)\n",
      "(709, 461) (792, 520)\n",
      "[16,   401] loss: 0.0007743\n",
      "(0.7594195008277893, 0.3991973400115967) (0.7792866230010986, 0.434162437915802)\n",
      "(0.7437499761581421, 0.40648147463798523) (0.7671874761581421, 0.43703705072402954)\n",
      "(1458, 431) (1496, 469)\n",
      "validation loss: 0.0153160\n",
      "SAVE\n",
      "[17,     1] loss: 0.0000032\n",
      "(0.8663696050643921, 0.4630395174026489) (0.8592534065246582, 0.5206032991409302)\n",
      "(0.8494791388511658, 0.5138888955116272) (0.8755208253860474, 0.5509259104728699)\n",
      "(1663, 500) (1650, 562)\n"
     ]
    }
   ],
   "source": [
    "val_loss = 1000 \n",
    "for epoch in range(EPOCH_NUM): \n",
    "\n",
    "#set the running loss at each epoch to zero\n",
    "    running_loss = 0.0\n",
    "# we will enumerate the train loader with starting index of 0\n",
    "# for each iteration (i) and the data (tuple of input and labels)\n",
    "    for i, data in enumerate(train_iterator, 0):\n",
    "        inputs, labels,fnames = data[0].cuda(), data[1].cuda(),data[2]\n",
    "        #print(labels)\n",
    "        # clear the gradient\n",
    "        #inputs, labels,fnames = data[0], data[1],data[2]\n",
    "        optimizer.zero_grad()\n",
    "        #feed the input and acquire the output from network\n",
    "        #outputs = net(inputs)\n",
    "        #outputs = torch.stack(list(net(inputs)), dim=0)\n",
    "        #outputs = outputs.to(torch.float32)\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs)\n",
    "        #outputs = outputs.reshape(-1)\n",
    "        #calculating the predicted and the expected loss\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #compute the gradient\n",
    "        #torch.cuda.empty_cache()\n",
    "        loss.backward()\n",
    "\n",
    "        #update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #print(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        prev_loss = 1\n",
    "        if i % 200 == 0:\n",
    "            print('[%d, %5d] loss: %.7f' % (epoch + 1, i + 1, running_loss/200))\n",
    "            \n",
    "            img = cv2.imread(os.path.join(folder,fnames[7]))\n",
    "            print((outputs[7][0].item(),outputs[7][1].item()),(outputs[7][2].item(),outputs[7][3].item()))\n",
    "            print((labels[7][0].item(),labels[7][1].item()),(labels[7][2].item(),labels[7][3].item()))\n",
    "            print((round(outputs[7][0].item()*img.shape[1]),round(outputs[7][1].item()*img.shape[0])),(round(outputs[7][2].item()*img.shape[1]),round(outputs[7][3].item()*img.shape[0])))#(outputs[7][0].item(),outputs[7][1].item()),(outputs[7][2].item(),outputs[7][3].item()))\n",
    "            #print((round(labels[7][0].item()*img.shape[1]),round(labels[7][1].item()*img.shape[0])),(round(labels[7][2].item()*img.shape[1]),round(labels[7][3].item()*img.shape[0])))#(labels[7][0].item(),labels[7][1].item()),(labels[7][2].item(),labels[7][3].item()))\n",
    "            #im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #im_rgb = cv2.rectangle(im_rgb,(round(outputs[7][0].item()*img.shape[1]),round(outputs[7][1].item()*img.shape[0])),(round(outputs[7][2].item()*img.shape[1]),round(outputs[7][3].item()*img.shape[0])),(255,0,0),2)\n",
    "            #im_rgb = cv2.rectangle(im_rgb,(round(labels[7][0].item()*img.shape[1]),round(labels[7][1].item()*img.shape[0])),(round(labels[7][2].item()*img.shape[1]),round(labels[7][3].item()*img.shape[0])),(0,0,255),2)\n",
    "            #plt.figure(figsize = (20,15))\n",
    "            #plt.imshow(im_rgb)\n",
    "            \n",
    "            #torch.save(net.state_dict(),\"net_epoch\"+str(epoch)+'_'+str(i)+'_loss='+str(running_loss)+'.pt')\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            \n",
    "        \n",
    "        \n",
    "    for i, data in enumerate(val_iterator, 0):\n",
    "        inputs, labels,fnames = data[0].cuda(), data[1].cuda(),data[2]\n",
    "        #print(labels)\n",
    "        # clear the gradient\n",
    "        #inputs, labels,fnames = data[0], data[1],data[2]\n",
    "        optimizer.zero_grad()\n",
    "        #feed the input and acquire the output from network\n",
    "        #outputs = net(inputs)\n",
    "        #outputs = torch.stack(list(net(inputs)), dim=0)\n",
    "        #outputs = outputs.to(torch.float32)\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs)\n",
    "        #outputs = outputs.reshape(-1)\n",
    "        #calculating the predicted and the expected loss\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # print statistics\n",
    "        #print(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('validation loss: %.7f' % (running_loss / i))\n",
    "\n",
    "    if running_loss/i < val_loss:\n",
    "        print('SAVE')\n",
    "        torch.save(model.state_dict(),\"flattened_model_net_epoch\"+str(epoch)+'_loss='+str(running_loss/i)+'.pt')\n",
    "        val_loss = running_loss/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_iterator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-45cbaee190c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_iterator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, data in enumerate(test_iterator, 0):\n",
    "    if i < 20 :\n",
    "        inputs, labels,fnames = data[0].cuda(), data[1].cuda(),data[2]\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        print('[%d] loss: %.7f' % ( i + 1, loss))\n",
    "        outputs = outputs.to(torch.float32)\n",
    "        img = cv2.imread(os.path.join(folder,fnames[7]))\n",
    "        print(img.shape)\n",
    "\n",
    "        print((outputs[7][0].item(),outputs[7][1].item()),(outputs[7][2].item(),outputs[7][3].item()))\n",
    "        print((labels[7][0].item(),labels[7][1].item()),(labels[7][2].item(),labels[7][3].item()))\n",
    "        #print((round(outputs[7][0].item()*img.shape[1]),round(outputs[7][1].item()*img.shape[0])),(round(outputs[7][2].item()*img.shape[1]),round(outputs[7][3].item()*img.shape[0])))#(outputs[7][0].item(),outputs[7][1].item()),(outputs[7][2].item(),outputs[7][3].item()))\n",
    "        #print((round(labels[7][0].item()*img.shape[1]),round(labels[7][1].item()*img.shape[0])),(round(labels[7][2].item()*img.shape[1]),round(labels[7][3].item()*img.shape[0])))#(labels[7][0].item(),labels[7][1].item()),(labels[7][2].item(),labels[7][3].item()))\n",
    "        im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        im_rgb = cv2.rectangle(im_rgb,(round(outputs[7][0].item()*img.shape[1]),round(outputs[7][1].item()*img.shape[0])),(round(outputs[7][2].item()*img.shape[1]),round(outputs[7][3].item()*img.shape[0])),(255,0,0),2)\n",
    "        im_rgb = cv2.rectangle(im_rgb,(round(labels[7][0].item()*img.shape[1]),round(labels[7][1].item()*img.shape[0])),(round(labels[7][2].item()*img.shape[1]),round(labels[7][3].item()*img.shape[0])),(0,0,255),2)\n",
    "        plt.figure(figsize = (20,15))\n",
    "        plt.imshow(im_rgb)\n",
    "        cv2.imwrite('testcase_{0}_coordinates.png'.format(i),im_rgb)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lain_new",
   "language": "python",
   "name": "lain_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
